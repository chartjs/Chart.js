#!/usr/bin/env python3
"""
Sales Lead Finder - South African Market Focus
Identifies potential leads based on public information while complying with POPIA regulations.

Disclaimer: This tool is for educational purposes only. Always consult with
legal experts to ensure full compliance with data protection laws.
"""

import requests
import time
import json
import re
import csv
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Set
from bs4 import BeautifulSoup
import pandas as pd

class SouthAfricanLeadFinder:
    def __init__(self):
        self.user_agent = "SalesLeadFinder/1.0 (Educational Use Only)"
        self.delay_between_requests = 2  # seconds between requests to be respectful
        self.min_price_threshold = 20000  # R20000 minimum value
        self.required_searches = 10  # 10 product searches minimum
        self.timeframe_days = 60  # Past 2 months
        
        # South African specific sources
        self.sa_business_directories = [
            "https://www.yellowpages.co.za",
            "https://www.hellopeter.com",
            "https://www.southafrican.com/directory/",
        ]
        
        self.sa_tender_portals = [
            "https://www.etenders.gov.za",
            "https://www.tenders.co.za",
        ]
        
        self.sa_forums = [
            "https://mybroadband.co.za/forum",
            "https://www.news24.com/fin24/forum",
        ]
        
        # POPIA compliance registry
        self.data_processing_register = []

    def search_sa_business_directories(self, keyword: str) -> List[Dict]:
        """
        Search South African business directories for relevant mentions.
        """
        results = []
        
        for directory in self.sa_business_directories:
            try:
                print(f"Searching {directory} for {keyword}...")
                # Example implementation for Yellow Pages South Africa
                if "yellowpages" in directory:
                    search_url = f"{directory}/search?q={keyword.replace(' ', '+')}"
                    headers = {'User-Agent': self.user_agent}
                    
                    response = requests.get(search_url, headers=headers, timeout=10)
                    time.sleep(self.delay_between_requests)
                    
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.text, 'html.parser')
                        
                        # Extract business listings (example selectors)
                        listings = soup.select('.listing__content')
                        
                        for listing in listings[:5]:  # Limit to first 5 results
                            try:
                                name_elem = listing.select_one('.listing__name')
                                biz_name = name_elem.text.strip() if name_elem else "Unknown Business"
                                
                                contact_elem = listing.select_one('.listing__contact')
                                contact = contact_elem.text.strip() if contact_elem else ""
                                
                                # Anonymize immediately for POPIA compliance
                                biz_hash = hash(biz_name)
                                
                                results.append({
                                    'source': directory,
                                    'business_hash': biz_hash,
                                    'keyword': keyword,
                                    'snippet': f"Business in {keyword} sector",
                                    'date_found': datetime.now().strftime("%Y-%m-%d"),
                                    'contact_available': bool(contact),
                                    # Don't store the actual contact info
                                })
                                
                                # Register this data processing activity for POPIA compliance
                                self.register_data_processing(
                                    source=directory,
                                    data_type="business listing",
                                    purpose="lead generation",
                                    lawful_basis="legitimate interest"
                                )
                                
                            except Exception as e:
                                print(f"Error parsing listing: {e}")
                                continue
                
                # Similar implementations for other directories would go here
                
            except Exception as e:
                print(f"Error searching {directory}: {e}")
                continue
        
        return results

    def search_sa_tenders(self, keyword: str) -> List[Dict]:
        """
        Search South African tender portals for high-value opportunities.
        """
        results = []
        
        for portal in self.sa_tender_portals:
            try:
                print(f"Searching {portal} for {keyword}...")
                
                # Example for etenders.gov.za
                if "etenders.gov.za" in portal:
                    search_url = f"{portal}/content/search?keywords={keyword.replace(' ', '+')}"
                    headers = {'User-Agent': self.user_agent}
                    
                    response = requests.get(search_url, headers=headers, timeout=10)
                    time.sleep(self.delay_between_requests)
                    
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.text, 'html.parser')
                        
                        # Extract tender listings (example selectors)
                        tenders = soup.select('.tender-item')
                        
                        for tender in tenders[:5]:  # Limit to first 5 results
                            try:
                                title_elem = tender.select_one('.tender-title')
                                title = title_elem.text.strip() if title_elem else "Unknown Tender"
                                
                                value_elem = tender.select_one('.tender-value')
                                value_text = value_elem.text.strip() if value_elem else ""
                                
                                # Extract value if possible
                                value_match = re.search(r'R\s*(\d+(?:[.,]\d+)*)', value_text)
                                value = float(value_match.group(1).replace(',', '')) if value_match else 0
                                
                                date_elem = tender.select_one('.tender-date')
                                date_str = date_elem.text.strip() if date_elem else ""
                                
                                # Check if tender is within our timeframe
                                tender_date = self.parse_date(date_str)
                                if tender_date and self.is_within_timeframe(tender_date):
                                    tender_hash = hash(title)
                                    
                                    results.append({
                                        'source': portal,
                                        'tender_hash': tender_hash,
                                        'keyword': keyword,
                                        'title_snippet': title[:100] + "..." if len(title) > 100 else title,
                                        'estimated_value': value,
                                        'date_found': tender_date.strftime("%Y-%m-%d"),
                                    })
                                    
                                    # Register this data processing activity for POPIA compliance
                                    self.register_data_processing(
                                        source=portal,
                                        data_type="tender information",
                                        purpose="lead generation",
                                        lawful_basis="publicly available information"
                                    )
                                
                            except Exception as e:
                                print(f"Error parsing tender: {e}")
                                continue
                
                # Similar implementations for other tender portals would go here
                
            except Exception as e:
                print(f"Error searching {portal}: {e}")
                continue
        
        return results

    def search_sa_forums(self, keyword: str) -> List[Dict]:
        """
        Search South African forums for product discussions.
        """
        results = []
        
        for forum in self.sa_forums:
            try:
                print(f"Searching {forum} for {keyword}...")
                
                # Example for MyBroadband forum
                if "mybroadband" in forum:
                    search_url = f"{forum}/search?q={keyword.replace(' ', '+')}"
                    headers = {'User-Agent': self.user_agent}
                    
                    response = requests.get(search_url, headers=headers, timeout=10)
                    time.sleep(self.delay_between_requests)
                    
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.text, 'html.parser')
                        
                        # Extract forum posts (example selectors)
                        posts = soup.select('.discussionListItem')
                        
                        for post in posts[:5]:  # Limit to first 5 results
                            try:
                                title_elem = post.select_one('.title')
                                title = title_elem.text.strip() if title_elem else "Unknown Post"
                                
                                author_elem = post.select_one('.username')
                                author = author_elem.text.strip() if author_elem else "Anonymous"
                                
                                date_elem = post.select_one('.DateTime')
                                date_str = date_elem.text.strip() if date_elem else ""
                                
                                # Check if post is within our timeframe
                                post_date = self.parse_date(date_str)
                                if post_date and self.is_within_timeframe(post_date):
                                    # Extract potential price mentions
                                    content_snippet = title  # In reality, we'd need to visit the post
                                    price_info = self.extract_price_info(content_snippet)
                                    
                                    if price_info and price_info['estimated_price'] >= self.min_price_threshold:
                                        author_hash = hash(author)
                                        
                                        results.append({
                                            'source': forum,
                                            'author_hash': author_hash,
                                            'keyword': keyword,
                                            'content_snippet': content_snippet[:200] + "..." if len(content_snippet) > 200 else content_snippet,
                                            'estimated_price': price_info['estimated_price'],
                                            'date_found': post_date.strftime("%Y-%m-%d"),
                                        })
                                        
                                        # Register this data processing activity for POPIA compliance
                                        self.register_data_processing(
                                            source=forum,
                                            data_type="forum post",
                                            purpose="lead generation",
                                            lawful_basis="legitimate interest"
                                        )
                                
                            except Exception as e:
                                print(f"Error parsing forum post: {e}")
                                continue
                
                # Similar implementations for other forums would go here
                
            except Exception as e:
                print(f"Error searching {forum}: {e}")
                continue
        
        return results

    def search_sa_companies_registry(self, keyword: str) -> List[Dict]:
        """
        Search South African companies registry for businesses in specific sectors.
        Note: This would typically require API access or proper data licensing.
        """
        results = []
        
        # This is a placeholder implementation
        # In reality, you would need to use the CIPC API or licensed data
        
        try:
            # Example of what you might do with proper access
            print(f"Searching companies registry for {keyword}...")
            
            # Simulate finding companies in a specific sector
            companies = [
                {"name": "XYZ Construction Pty Ltd", "sector": "construction", "registration": "2020/123456/07"},
                {"name": "ABC Manufacturing SA", "sector": "manufacturing", "registration": "2019/987654/07"},
            ]
            
            for company in companies:
                if keyword.lower() in company['sector']:
                    company_hash = hash(company['name'])
                    
                    results.append({
                        'source': 'CIPC Registry (simulated)',
                        'company_hash': company_hash,
                        'keyword': keyword,
                        'sector': company['sector'],
                        'date_found': datetime.now().strftime("%Y-%m-%d"),
                    })
                    
                    # Register this data processing activity for POPIA compliance
                    self.register_data_processing(
                        source="CIPC Registry",
                        data_type="company information",
                        purpose="lead generation",
                        lawful_basis="public register"
                    )
            
        except Exception as e:
            print(f"Error searching companies registry: {e}")
        
        return results

    def parse_date(self, date_str: str) -> Optional[datetime]:
        """
        Parse various South African date formats.
        """
        try:
            # Try common SA date formats
            formats = [
                "%d-%m-%Y", "%d/%m/%Y", "%Y-%m-%d",
                "%d %b %Y", "%d %B %Y",
            ]
            
            for fmt in formats:
                try:
                    return datetime.strptime(date_str, fmt)
                except ValueError:
                    continue
            
            # Try relative dates (e.g., "2 days ago")
            if "ago" in date_str.lower():
                match = re.search(r'(\d+)\s+(day|week|month)', date_str.lower())
                if match:
                    num, unit = int(match.group(1)), match.group(2)
                    if unit == "day":
                        return datetime.now() - timedelta(days=num)
                    elif unit == "week":
                        return datetime.now() - timedelta(weeks=num)
                    elif unit == "month":
                        return datetime.now() - timedelta(days=30*num)
            
            return None
        except:
            return None

    def is_within_timeframe(self, date: datetime) -> bool:
        """
        Check if a date is within our 2-month timeframe.
        """
        cutoff_date = datetime.now() - timedelta(days=self.timeframe_days)
        return date >= cutoff_date

    def extract_price_info(self, content: str) -> Optional[Dict]:
        """
        Extract price information from text, focusing on South African formats.
        """
        # South African price patterns (Rand)
        price_patterns = [
            r'r\s*(\d+(?:[.,]\d+)*(?:\s*(?:thousand|k|rand|rands))?)',
            r'zar\s*(\d+(?:[.,]\d+)*)',
            r'budget.*?r?\s*(\d+(?:[.,]\d+)*)',
            r'approximately.*?r?\s*(\d+(?:[.,]\d+)*)',
            r'price.*?r?\s*(\d+(?:[.,]\d+)*)',
        ]
        
        prices = []
        for pattern in price_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                # Clean the price string
                price_str = re.sub(r'[^\d.,]', '', match)
                price_str = price_str.replace(',', '').replace(' ', '')
                
                # Handle thousand/k notation
                if 'thousand' in match.lower() or 'k' in match.lower():
                    try:
                        price = float(price_str) * 1000
                        prices.append(price)
                    except ValueError:
                        continue
                else:
                    try:
                        price = float(price_str)
                        prices.append(price)
                    except ValueError:
                        continue
        
        if prices:
            return {
                "estimated_price": max(prices),  # Use the highest mentioned price
                "price_evidence": content[:200] + "..."  # Keep only snippet for evidence
            }
        
        return None

    def register_data_processing(self, source: str, data_type: str, purpose: str, lawful_basis: str):
        """
        Register data processing activities for POPIA compliance.
        """
        processing_record = {
            "timestamp": datetime.now().isoformat(),
            "source": source,
            "data_type": data_type,
            "purpose": purpose,
            "lawful_basis": lawful_basis,
            "data_minimized": True,
            "anonymized": True,
            "security_measures": "encryption, access controls"
        }
        
        self.data_processing_register.append(processing_record)

    def is_potential_lead(self, search_history: List[Dict]) -> bool:
        """
        Determine if the collected information meets lead criteria.
        """
        if len(search_history) < self.required_searches:
            return False
        
        high_value_searches = [
            search for search in search_history 
            if search.get('estimated_price', 0) >= self.min_price_threshold
        ]
        
        return len(high_value_searches) >= self.required_searches

    def find_leads(self, product_keywords: List[str]) -> List[Dict]:
        """
        Main method to find potential leads based on product keywords.
        """
        potential_leads = {}
        
        for keyword in product_keywords:
            print(f"Searching for mentions of: {keyword}")
            
            # Search various South African sources
            business_results = self.search_sa_business_directories(keyword)
            tender_results = self.search_sa_tenders(keyword)
            forum_results = self.search_sa_forums(keyword)
            company_results = self.search_sa_companies_registry(keyword)
            
            # Combine all results
            all_results = business_results + tender_results + forum_results + company_results
            
            for result in all_results:
                # Group by entity (using hashed identifier)
                entity_id = result.get('business_hash') or result.get('tender_hash') or result.get('author_hash') or result.get('company_hash')
                
                if not entity_id:
                    continue
                
                if entity_id not in potential_leads:
                    potential_leads[entity_id] = []
                
                potential_leads[entity_id].append(result)
            
            # Be respectful with rate limiting
            time.sleep(self.delay_between_requests)
        
        # Filter to only those meeting our criteria
        confirmed_leads = {}
        for entity_id, searches in potential_leads.items():
            if self.is_potential_lead(searches):
                # Store only necessary information
                confirmed_leads[entity_id] = {
                    "search_count": len(searches),
                    "first_seen": min(s.get('date_found', '') for s in searches),
                    "last_seen": max(s.get('date_found', '') for s in searches),
                    "max_price": max(s.get('estimated_price', 0) for s in searches if 'estimated_price' in s),
                    "evidence_samples": [s.get('content_snippet', '') for s in searches[:3]],
                    "sources": list(set(s.get('source', '') for s in searches))
                }
        
        return confirmed_leads

    def generate_popia_report(self) -> str:
        """
        Generate a POPIA compliance report.
        """
        report = [
            "POPIA COMPLIANCE REPORT",
            "=======================",
            f"Report generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            f"Data processing activities recorded: {len(self.data_processing_register)}",
            "",
            "DATA PROCESSING ACTIVITIES:",
            "--------------------------"
        ]
        
        for i, activity in enumerate(self.data_processing_register, 1):
            report.extend([
                f"Activity {i}:",
                f"- Source: {activity['source']}",
                f"- Data Type: {activity['data_type']}",
                f"- Purpose: {activity['purpose']}",
                f"- Lawful Basis: {activity['lawful_basis']}",
                f"- Data Minimized: {activity['data_minimized']}",
                f"- Anonymized: {activity['anonymized']}",
                f"- Security Measures: {activity['security_measures']}",
                f"- Timestamp: {activity['timestamp']}",
                ""
            ])
        
        report.extend([
            "POPIA COMPLIANCE NOTES:",
            "-----------------------",
            "1. No personally identifiable information is stored",
            "2. All data was collected from publicly available sources only",
            "3. Data processing activities have been recorded as required by POPIA",
            "4. Data minimization principles have been applied",
            "5. Appropriate security measures are in place",
            "6. Data subjects can request information via our PAIA manual",
            "",
            "NOTE: This tool is designed for compliance with South Africa's POPIA Act,",
            "but should be reviewed by legal professionals before use in production."
        ])
        
        return "\n".join(report)

    def generate_leads_report(self, leads: Dict[str, Dict]) -> str:
        """
        Generate a leads report without personal information.
        """
        report = [
            "SALES LEADS REPORT - SOUTH AFRICAN MARKET",
            "==========================================",
            f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            f"Timeframe: Past {self.timeframe_days} days",
            f"Criteria: At least {self.required_searches} product searches valued over R{self.min_price_threshold}",
            f"Total leads found: {len(leads)}",
            "",
            "LEAD SUMMARY:",
            "-------------"
        ]
        
        for i, (entity_hash, data) in enumerate(leads.items(), 1):
            report.extend([
                f"Lead #{i}:",
                f"- Anonymous ID: {entity_hash}",
                f"- Activity period: {data['first_seen']} to {data['last_seen']}",
                f"- Total relevant searches: {data['search_count']}",
                f"- Maximum budget indication: R{data.get('max_price', 0):,.2f}",
                f"- Sources: {', '.join(data['sources'])}",
                "- Sample evidence:",
            ])
            
            for evidence in data['evidence_samples']:
                report.append(f"  * {evidence}")
            
            report.append("")
        
        return "\n".join(report)

    def save_reports(self, leads: Dict[str, Dict]):
        """
        Save both leads and POPIA compliance reports.
        """
        # Save leads report
        leads_report = self.generate_leads_report(leads)
        with open("sa_sales_leads_report.txt", "w") as f:
            f.write(leads_report)
        
        # Save POPIA compliance report
        popia_report = self.generate_popia_report()
        with open("popia_compliance_report.txt", "w") as f:
            f.write(popia_report)
        
        # Save data processing register as JSON
        with open("data_processing_register.json", "w") as f:
            json.dump(self.data_processing_register, f, indent=2)
        
        print(f"Reports generated with {len(leads)} potential leads.")
        print("Files created:")
        print("- sa_sales_leads_report.txt")
        print("- popia_compliance_report.txt")
        print("- data_processing_register.json")


def main():
    """
    Example usage for South African market.
    """
    # Initialize the lead finder
    lead_finder = SouthAfricanLeadFinder()
    
    # Define products relevant to South African market
    sa_products_of_interest = [
        "construction equipment",
        "mining machinery",
        "agricultural machinery",
        "solar power systems",
        "water treatment plants",
        "commercial vehicles",
        "industrial generators",
        "security systems",
        "office furniture",
        "IT infrastructure"
    ]
    
    print("Starting South African lead generation process...")
    print("This may take a while as we respect rate limiting...")
    
    # Find potential leads
    leads = lead_finder.find_leads(sa_products_of_interest)
    
    # Save reports
    lead_finder.save_reports(leads)
    
    print("Process completed. Please review the reports.")


if __name__ == "__main__":
    main()
